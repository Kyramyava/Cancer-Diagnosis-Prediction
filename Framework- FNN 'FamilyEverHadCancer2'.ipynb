{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['public'])\n",
      "       Age   AsAm  AmerInd  AvgDrinksPerWeek  Black  DrinkDaysPerWeek  \\\n",
      "0     83.0  False      0.0               0.0    0.0               0.0   \n",
      "1     58.0  False      0.0              35.0    0.0               7.0   \n",
      "2     40.0  False      0.0               0.0    0.0               0.0   \n",
      "3     66.0  False      0.0               0.0    0.0               0.0   \n",
      "4     39.0  False      0.0               0.0    1.0               0.0   \n",
      "...    ...    ...      ...               ...    ...               ...   \n",
      "6247  48.0  False      0.0               4.0    0.0               2.0   \n",
      "6248  50.0  False      0.0               0.0    0.0               0.0   \n",
      "6249  55.0  False      0.0               3.0    1.0               1.0   \n",
      "6250  62.0  False      0.0              84.0    0.0               7.0   \n",
      "6251  57.0  False      0.0               0.0    0.0               0.0   \n",
      "\n",
      "      DrinksOneOccasion  DrinksPerDay  Education  EverHadCancer  ...  \\\n",
      "0                   0.0           2.0        1.0            0.0  ...   \n",
      "1                  11.0           5.0        6.0            0.0  ...   \n",
      "2                   0.0           2.0        6.0            0.0  ...   \n",
      "3                   1.5           2.0        3.0            0.0  ...   \n",
      "4                   0.0           2.0        6.0            0.0  ...   \n",
      "...                 ...           ...        ...            ...  ...   \n",
      "6247                0.0           2.0        6.0            0.0  ...   \n",
      "6248                0.0           2.0        5.0            0.0  ...   \n",
      "6249                1.5           3.0        3.0            0.0  ...   \n",
      "6250                8.0          12.0        3.0            0.0  ...   \n",
      "6251                0.0           2.0        6.0            0.0  ...   \n",
      "\n",
      "      SmokeNow_Not at all  SmokeNow_Some days  \\\n",
      "0                    True               False   \n",
      "1                    True               False   \n",
      "2                   False               False   \n",
      "3                    True               False   \n",
      "4                    True               False   \n",
      "...                   ...                 ...   \n",
      "6247                 True               False   \n",
      "6248                 True               False   \n",
      "6249                False               False   \n",
      "6250                False               False   \n",
      "6251                 True               False   \n",
      "\n",
      "      SunEffectAfter1Hour_Burn mildly with some or no tanning  \\\n",
      "0                                                 False         \n",
      "1                                                 False         \n",
      "2                                                 False         \n",
      "3                                                  True         \n",
      "4                                                 False         \n",
      "...                                                 ...         \n",
      "6247                                              False         \n",
      "6248                                              False         \n",
      "6249                                              False         \n",
      "6250                                               True         \n",
      "6251                                              False         \n",
      "\n",
      "      SunEffectAfter1Hour_Get a severe sunburn with blisters  \\\n",
      "0                                                 False        \n",
      "1                                                 False        \n",
      "2                                                 False        \n",
      "3                                                 False        \n",
      "4                                                 False        \n",
      "...                                                 ...        \n",
      "6247                                              False        \n",
      "6248                                              False        \n",
      "6249                                              False        \n",
      "6250                                              False        \n",
      "6251                                              False        \n",
      "\n",
      "      SunEffectAfter1Hour_Have a moderate sunburn with peeling  \\\n",
      "0                                                 False          \n",
      "1                                                 False          \n",
      "2                                                 False          \n",
      "3                                                 False          \n",
      "4                                                 False          \n",
      "...                                                 ...          \n",
      "6247                                              False          \n",
      "6248                                              False          \n",
      "6249                                              False          \n",
      "6250                                              False          \n",
      "6251                                              False          \n",
      "\n",
      "      SunEffectAfter1Hour_Nothing would happen to my skin  \\\n",
      "0                                                  True     \n",
      "1                                                 False     \n",
      "2                                                 False     \n",
      "3                                                 False     \n",
      "4                                                  True     \n",
      "...                                                 ...     \n",
      "6247                                               True     \n",
      "6248                                              False     \n",
      "6249                                              False     \n",
      "6250                                              False     \n",
      "6251                                               True     \n",
      "\n",
      "      SunEffectAfter1Hour_Turn darker without sunburn  UseECigNow_Everyday  \\\n",
      "0                                               False                False   \n",
      "1                                                True                False   \n",
      "2                                               False                False   \n",
      "3                                               False                False   \n",
      "4                                               False                False   \n",
      "...                                               ...                  ...   \n",
      "6247                                            False                False   \n",
      "6248                                             True                False   \n",
      "6249                                            False                False   \n",
      "6250                                            False                False   \n",
      "6251                                            False                False   \n",
      "\n",
      "      UseECigNow_Not at all  UseECigNow_Some days  \n",
      "0                     False                 False  \n",
      "1                     False                 False  \n",
      "2                     False                 False  \n",
      "3                     False                 False  \n",
      "4                     False                 False  \n",
      "...                     ...                   ...  \n",
      "6247                  False                 False  \n",
      "6248                  False                 False  \n",
      "6249                   True                 False  \n",
      "6250                  False                 False  \n",
      "6251                  False                 False  \n",
      "\n",
      "[6252 rows x 59 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define path\n",
    "file_path = r\"C:\\Users\\kyram\\OneDrive\\School\\Prepossesed Data.json\"\n",
    "\n",
    "# Confirm the file exists\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"The file does not exist at the specified path: {file_path}\")\n",
    "else:\n",
    "    # Load the JSON \n",
    "    with open(file_path, 'r') as file:\n",
    "        preprocessed_data = json.load(file)\n",
    "\n",
    "    # Print the keys\n",
    "    print(preprocessed_data.keys())\n",
    "\n",
    "    # Access the key\n",
    "    if 'public' in preprocessed_data:\n",
    "        public_data = preprocessed_data['public']\n",
    "        # Convert the dictionary back to a DataFrame\n",
    "        df = pd.DataFrame.from_dict(public_data)\n",
    "        print(df)\n",
    "    else:\n",
    "        print(\"'public' key not found in the JSON file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import tensorflow \n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "X = df.copy().drop(['EverHadCancer', 'FamilyEverHadCancer2'], axis=1)\n",
    "\n",
    "y = df['FamilyEverHadCancer2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode y\n",
    "label_encoder = LabelEncoder()\n",
    "y_numeric = label_encoder.fit_transform(y)\n",
    "\n",
    "# Impute X\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale X\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "X_imputed = numerical_transformer.fit_transform(X_imputed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y_numeric, test_size=0.2, random_state=42, stratify=y_numeric)\n",
    "\n",
    "# Resample\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (6252, 59)\n",
      "Dataset distribution: Counter({'Age': 1, 'AsAm': 1, 'AmerInd': 1, 'AvgDrinksPerWeek': 1, 'Black': 1, 'DrinkDaysPerWeek': 1, 'DrinksOneOccasion': 1, 'DrinksPerDay': 1, 'Education': 1, 'EverHadCancer': 1, 'FamilyEverHadCancer2': 1, 'FreqGoProvider': 1, 'HealthInsurance2': 1, 'HeardHPVVaccine2': 1, 'HPVCauseCancer_Cervical': 1, 'Hisp': 1, 'IncomeRanges': 1, 'MedConditions_Diabetes': 1, 'MedConditions_HighBP': 1, 'MedConditions_HeartCondition': 1, 'MedConditions_LungDisease': 1, 'OthPacIsl': 1, 'Smoke100': 1, 'Sunburned_Active': 1, 'Sunburned_Other': 1, 'Sunburned_Rec': 1, 'Sunburned_Work': 1, 'TimesSunburned': 1, 'UsedECigEver': 1, 'WhenPapTest': 1, 'White': 1, 'BirthGender_Female': 1, 'BirthGender_Male': 1, 'DelayNeededCare_I did not need any medical care in the past 12 months': 1, 'DelayNeededCare_No, I received the medical care I felt I needed': 1, 'DelayNeededCare_Yes': 1, 'DocTalkLDCT_Dont know': 1, 'DocTalkLDCT_I have never heard of this test': 1, 'DocTalkLDCT_No': 1, 'DocTalkLDCT_Yes': 1, 'DocTellColorectalTests_I have never discussed these tests with a doctor or other he': 1, 'DocTellColorectalTests_No': 1, 'DocTellColorectalTests_Yes': 1, 'QualityCare_Excellent': 1, 'QualityCare_Fair': 1, 'QualityCare_Good': 1, 'QualityCare_Poor': 1, 'QualityCare_Very good': 1, 'SmokeNow_Everyday': 1, 'SmokeNow_Not at all': 1, 'SmokeNow_Some days': 1, 'SunEffectAfter1Hour_Burn mildly with some or no tanning': 1, 'SunEffectAfter1Hour_Get a severe sunburn with blisters': 1, 'SunEffectAfter1Hour_Have a moderate sunburn with peeling': 1, 'SunEffectAfter1Hour_Nothing would happen to my skin': 1, 'SunEffectAfter1Hour_Turn darker without sunburn': 1, 'UseECigNow_Everyday': 1, 'UseECigNow_Not at all': 1, 'UseECigNow_Some days': 1})\n",
      "X_test shape: (1251, 57)\n",
      "y_test shape: (1251,)\n",
      "y_test Dataset distribution: Counter({1: 799, 0: 452})\n",
      "X__train_resampled Shape (6388, 57)\n",
      "y_train_resampled Shape (6388,)\n",
      "y_train_resampled Dataset distribution: Counter({1: 3194, 0: 3194})\n"
     ]
    }
   ],
   "source": [
    "# Check shapes and distributions\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"Dataset distribution:\", Counter(df))\n",
    "\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "print(\"y_test Dataset distribution:\", Counter(y_test))\n",
    "\n",
    "print(\"X__train_resampled Shape\", X_train_resampled.shape)\n",
    "print(\"y_train_resampled Shape\", y_train_resampled.shape)\n",
    "print(\"y_train_resampled Dataset distribution:\", Counter(y_train_resampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "160/160 [==============================] - 2s 5ms/step - loss: 0.6160 - accuracy: 0.6736 - val_loss: 0.8405 - val_accuracy: 0.4053\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.5609 - accuracy: 0.7104 - val_loss: 0.7999 - val_accuracy: 0.4546\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.7233 - val_loss: 0.6613 - val_accuracy: 0.5352\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7315 - val_loss: 0.7687 - val_accuracy: 0.4812\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7446 - val_loss: 0.7970 - val_accuracy: 0.4397\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.4981 - accuracy: 0.7511 - val_loss: 0.7602 - val_accuracy: 0.4679\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.4839 - accuracy: 0.7605 - val_loss: 0.6650 - val_accuracy: 0.5673\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.4707 - accuracy: 0.7693 - val_loss: 0.6776 - val_accuracy: 0.5689\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.4569 - accuracy: 0.7802 - val_loss: 0.7245 - val_accuracy: 0.5211\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.4439 - accuracy: 0.7920 - val_loss: 0.6009 - val_accuracy: 0.6362\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7994 - val_loss: 0.6060 - val_accuracy: 0.6291\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.4114 - accuracy: 0.8063 - val_loss: 0.4488 - val_accuracy: 0.7582\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.3988 - accuracy: 0.8205 - val_loss: 0.4576 - val_accuracy: 0.7504\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.3845 - accuracy: 0.8286 - val_loss: 0.5442 - val_accuracy: 0.6901\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8360 - val_loss: 0.4762 - val_accuracy: 0.7308\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8511 - val_loss: 0.4722 - val_accuracy: 0.7543\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8544 - val_loss: 0.4948 - val_accuracy: 0.7394\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8614 - val_loss: 0.4386 - val_accuracy: 0.7911\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8767 - val_loss: 0.3296 - val_accuracy: 0.8513\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.3018 - accuracy: 0.8753 - val_loss: 0.3793 - val_accuracy: 0.8200\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2934 - accuracy: 0.8828 - val_loss: 0.3761 - val_accuracy: 0.8271\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.8924 - val_loss: 0.3730 - val_accuracy: 0.8255\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2706 - accuracy: 0.8961 - val_loss: 0.3389 - val_accuracy: 0.8419\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2574 - accuracy: 0.9018 - val_loss: 0.3762 - val_accuracy: 0.8161\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2476 - accuracy: 0.9090 - val_loss: 0.3352 - val_accuracy: 0.8451\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2392 - accuracy: 0.9094 - val_loss: 0.2595 - val_accuracy: 0.8967\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2288 - accuracy: 0.9141 - val_loss: 0.3587 - val_accuracy: 0.8365\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2204 - accuracy: 0.9221 - val_loss: 0.2331 - val_accuracy: 0.9108\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2112 - accuracy: 0.9233 - val_loss: 0.2602 - val_accuracy: 0.8983\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.2035 - accuracy: 0.9290 - val_loss: 0.2497 - val_accuracy: 0.9022\n",
      "Epoch 31/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9295 - val_loss: 0.2205 - val_accuracy: 0.9194\n",
      "Epoch 32/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1864 - accuracy: 0.9370 - val_loss: 0.2393 - val_accuracy: 0.9108\n",
      "Epoch 33/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1807 - accuracy: 0.9393 - val_loss: 0.2327 - val_accuracy: 0.9022\n",
      "Epoch 34/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1728 - accuracy: 0.9403 - val_loss: 0.2141 - val_accuracy: 0.9233\n",
      "Epoch 35/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1661 - accuracy: 0.9427 - val_loss: 0.2736 - val_accuracy: 0.8944\n",
      "Epoch 36/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.1586 - accuracy: 0.9495 - val_loss: 0.1705 - val_accuracy: 0.9484\n",
      "Epoch 37/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1511 - accuracy: 0.9534 - val_loss: 0.2470 - val_accuracy: 0.8959\n",
      "Epoch 38/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1462 - accuracy: 0.9540 - val_loss: 0.1806 - val_accuracy: 0.9429\n",
      "Epoch 39/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1402 - accuracy: 0.9579 - val_loss: 0.1658 - val_accuracy: 0.9491\n",
      "Epoch 40/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1321 - accuracy: 0.9603 - val_loss: 0.1778 - val_accuracy: 0.9421\n",
      "Epoch 41/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1286 - accuracy: 0.9618 - val_loss: 0.1878 - val_accuracy: 0.9460\n",
      "Epoch 42/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1203 - accuracy: 0.9646 - val_loss: 0.1356 - val_accuracy: 0.9718\n",
      "Epoch 43/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1156 - accuracy: 0.9669 - val_loss: 0.1118 - val_accuracy: 0.9750\n",
      "Epoch 44/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1097 - accuracy: 0.9712 - val_loss: 0.1186 - val_accuracy: 0.9703\n",
      "Epoch 45/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.9706 - val_loss: 0.2169 - val_accuracy: 0.9257\n",
      "Epoch 46/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1011 - accuracy: 0.9730 - val_loss: 0.1270 - val_accuracy: 0.9624\n",
      "Epoch 47/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0952 - accuracy: 0.9761 - val_loss: 0.1074 - val_accuracy: 0.9734\n",
      "Epoch 48/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0922 - accuracy: 0.9771 - val_loss: 0.1279 - val_accuracy: 0.9687\n",
      "Epoch 49/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9802 - val_loss: 0.0997 - val_accuracy: 0.9789\n",
      "Epoch 50/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0810 - accuracy: 0.9832 - val_loss: 0.0931 - val_accuracy: 0.9867\n",
      "Epoch 51/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0783 - accuracy: 0.9822 - val_loss: 0.0816 - val_accuracy: 0.9867\n",
      "Epoch 52/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0751 - accuracy: 0.9861 - val_loss: 0.1019 - val_accuracy: 0.9789\n",
      "Epoch 53/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0698 - accuracy: 0.9861 - val_loss: 0.0789 - val_accuracy: 0.9828\n",
      "Epoch 54/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.9877 - val_loss: 0.0525 - val_accuracy: 0.9945\n",
      "Epoch 55/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9871 - val_loss: 0.0681 - val_accuracy: 0.9883\n",
      "Epoch 56/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0602 - accuracy: 0.9896 - val_loss: 0.0736 - val_accuracy: 0.9906\n",
      "Epoch 57/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9910 - val_loss: 0.0612 - val_accuracy: 0.9922\n",
      "Epoch 58/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9894 - val_loss: 0.1267 - val_accuracy: 0.9593\n",
      "Epoch 59/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9869 - val_loss: 0.0692 - val_accuracy: 0.9875\n",
      "Epoch 60/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0484 - accuracy: 0.9928 - val_loss: 0.0676 - val_accuracy: 0.9859\n",
      "Epoch 61/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0465 - accuracy: 0.9926 - val_loss: 0.0747 - val_accuracy: 0.9859\n",
      "Epoch 62/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.9924 - val_loss: 0.0424 - val_accuracy: 0.9969\n",
      "Epoch 63/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0407 - accuracy: 0.9947 - val_loss: 0.0296 - val_accuracy: 0.9984\n",
      "Epoch 64/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0413 - accuracy: 0.9959 - val_loss: 0.0486 - val_accuracy: 0.9930\n",
      "Epoch 65/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9941 - val_loss: 0.0603 - val_accuracy: 0.9844\n",
      "Epoch 66/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0338 - accuracy: 0.9969 - val_loss: 0.0292 - val_accuracy: 0.9961\n",
      "Epoch 67/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.9959 - val_loss: 0.0629 - val_accuracy: 0.9906\n",
      "Epoch 68/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9914 - val_loss: 0.0318 - val_accuracy: 0.9977\n",
      "Epoch 69/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0606 - accuracy: 0.9826 - val_loss: 0.0466 - val_accuracy: 0.9898\n",
      "Epoch 70/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0556 - accuracy: 0.9883 - val_loss: 0.0521 - val_accuracy: 0.9898\n",
      "Epoch 71/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0427 - accuracy: 0.9906 - val_loss: 0.0572 - val_accuracy: 0.9890\n",
      "Epoch 72/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9943 - val_loss: 0.0545 - val_accuracy: 0.9961\n",
      "Epoch 73/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0284 - accuracy: 0.9967 - val_loss: 0.0205 - val_accuracy: 0.9969\n",
      "Epoch 74/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9980 - val_loss: 0.0320 - val_accuracy: 0.9984\n",
      "Epoch 75/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0200 - accuracy: 0.9986 - val_loss: 0.0213 - val_accuracy: 0.9992\n",
      "Epoch 76/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0176 - accuracy: 0.9992 - val_loss: 0.0290 - val_accuracy: 0.9992\n",
      "Epoch 77/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0169 - accuracy: 0.9994 - val_loss: 0.0283 - val_accuracy: 0.9969\n",
      "Epoch 78/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9988 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0173 - accuracy: 0.9992 - val_loss: 0.0224 - val_accuracy: 0.9992\n",
      "Epoch 80/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0158 - accuracy: 0.9988 - val_loss: 0.0174 - val_accuracy: 0.9992\n",
      "Epoch 81/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9992 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0203 - accuracy: 0.9980 - val_loss: 0.0256 - val_accuracy: 0.9953\n",
      "Epoch 83/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 0.9984 - val_loss: 0.0207 - val_accuracy: 0.9984\n",
      "Epoch 84/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9949 - val_loss: 0.0554 - val_accuracy: 0.9851\n",
      "Epoch 85/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0822 - accuracy: 0.9685 - val_loss: 0.0718 - val_accuracy: 0.9773\n",
      "Epoch 86/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.1027 - accuracy: 0.9654 - val_loss: 0.0609 - val_accuracy: 0.9789\n",
      "Epoch 87/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 0.9873 - val_loss: 0.0346 - val_accuracy: 0.9898\n",
      "Epoch 88/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.0222 - val_accuracy: 0.9992\n",
      "Epoch 89/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9996 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9998 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9992\n",
      "Epoch 92/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9992\n",
      "Epoch 94/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0096 - accuracy: 0.9992 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.9996 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0099 - accuracy: 0.9984 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9994 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0108 - accuracy: 0.9990 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0903 - accuracy: 0.6195\n",
      "Loss: 3.090261220932007, Accuracy: 0.6195043921470642\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "F1 Score: 0.6189449031724862\n",
      "Confusion Matrix:\n",
      "[[211 241]\n",
      " [235 564]]\n"
     ]
    }
   ],
   "source": [
    "# Set seed\n",
    "random.seed(42)\n",
    "\n",
    "# Define model\n",
    "model_1 = Sequential([\n",
    "    Dense(57, activation='relu', input_shape=(57,)),  \n",
    "    Dense(30, activation='relu'), \n",
    "    Dense(len(np.unique(y_numeric)), activation='softmax') \n",
    "])\n",
    "\n",
    "\n",
    "# Compile model \n",
    "model_1.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model \n",
    "model_1.fit(X_train_resampled, y_train_resampled, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate model \n",
    "loss_1, accuracy_1 = model_1.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss_1}, Accuracy: {accuracy_1}')\n",
    "\n",
    "# Predict y\n",
    "y_pred_1 = model_1.predict(X_test)\n",
    "y_pred_classes_1 = np.argmax(y_pred_1, axis=1)\n",
    "\n",
    "# F1 score and confusion matrix\n",
    "f1_1 = f1_score(y_test, y_pred_classes_1, average='weighted')\n",
    "conf_matrix_1 = confusion_matrix(y_test, y_pred_classes_1)\n",
    "\n",
    "print(f'F1 Score: {f1_1}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "160/160 [==============================] - 2s 5ms/step - loss: 0.6347 - accuracy: 0.6581 - val_loss: 0.8107 - val_accuracy: 0.4225\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.5705 - accuracy: 0.7153 - val_loss: 0.8477 - val_accuracy: 0.3850\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.5442 - accuracy: 0.7241 - val_loss: 0.7258 - val_accuracy: 0.5047\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.5235 - accuracy: 0.7413 - val_loss: 0.6376 - val_accuracy: 0.5704\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.5080 - accuracy: 0.7519 - val_loss: 0.7279 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.4873 - accuracy: 0.7703 - val_loss: 0.6050 - val_accuracy: 0.6135\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.4701 - accuracy: 0.7824 - val_loss: 0.5581 - val_accuracy: 0.6659\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.4515 - accuracy: 0.7865 - val_loss: 0.6061 - val_accuracy: 0.6291\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.4327 - accuracy: 0.8051 - val_loss: 0.5823 - val_accuracy: 0.6643\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.4149 - accuracy: 0.8098 - val_loss: 0.6418 - val_accuracy: 0.6033\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.3950 - accuracy: 0.8252 - val_loss: 0.5615 - val_accuracy: 0.6831\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.3759 - accuracy: 0.8405 - val_loss: 0.4604 - val_accuracy: 0.7723\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.3598 - accuracy: 0.8440 - val_loss: 0.4259 - val_accuracy: 0.7700\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.3424 - accuracy: 0.8591 - val_loss: 0.4217 - val_accuracy: 0.7879\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.3200 - accuracy: 0.8661 - val_loss: 0.4013 - val_accuracy: 0.8028\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.3025 - accuracy: 0.8759 - val_loss: 0.3760 - val_accuracy: 0.8114\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.2865 - accuracy: 0.8818 - val_loss: 0.3328 - val_accuracy: 0.8498\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.2705 - accuracy: 0.8900 - val_loss: 0.3580 - val_accuracy: 0.8365\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.2531 - accuracy: 0.9049 - val_loss: 0.3000 - val_accuracy: 0.8584\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.2385 - accuracy: 0.9088 - val_loss: 0.2660 - val_accuracy: 0.8912\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.2251 - accuracy: 0.9186 - val_loss: 0.2344 - val_accuracy: 0.8967\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.2115 - accuracy: 0.9194 - val_loss: 0.2539 - val_accuracy: 0.8951\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1947 - accuracy: 0.9321 - val_loss: 0.2292 - val_accuracy: 0.9085\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1835 - accuracy: 0.9319 - val_loss: 0.2614 - val_accuracy: 0.8959\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.1705 - accuracy: 0.9417 - val_loss: 0.1870 - val_accuracy: 0.9202\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1593 - accuracy: 0.9448 - val_loss: 0.1540 - val_accuracy: 0.9460\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1493 - accuracy: 0.9499 - val_loss: 0.1796 - val_accuracy: 0.9257\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.1360 - accuracy: 0.9556 - val_loss: 0.1284 - val_accuracy: 0.9648\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.1287 - accuracy: 0.9571 - val_loss: 0.1402 - val_accuracy: 0.9468\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9624 - val_loss: 0.1321 - val_accuracy: 0.9617\n",
      "Epoch 31/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1111 - accuracy: 0.9667 - val_loss: 0.1171 - val_accuracy: 0.9671\n",
      "Epoch 32/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.1147 - accuracy: 0.9630 - val_loss: 0.1372 - val_accuracy: 0.9484\n",
      "Epoch 33/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.1036 - accuracy: 0.9695 - val_loss: 0.1458 - val_accuracy: 0.9366\n",
      "Epoch 34/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0940 - accuracy: 0.9720 - val_loss: 0.0938 - val_accuracy: 0.9773\n",
      "Epoch 35/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 0.9793 - val_loss: 0.1000 - val_accuracy: 0.9679\n",
      "Epoch 36/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0746 - accuracy: 0.9816 - val_loss: 0.0528 - val_accuracy: 0.9890\n",
      "Epoch 37/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0690 - accuracy: 0.9847 - val_loss: 0.0724 - val_accuracy: 0.9867\n",
      "Epoch 38/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0623 - accuracy: 0.9861 - val_loss: 0.0701 - val_accuracy: 0.9844\n",
      "Epoch 39/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0589 - accuracy: 0.9861 - val_loss: 0.0484 - val_accuracy: 0.9914\n",
      "Epoch 40/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9888 - val_loss: 0.0799 - val_accuracy: 0.9867\n",
      "Epoch 41/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0624 - accuracy: 0.9830 - val_loss: 0.0959 - val_accuracy: 0.9671\n",
      "Epoch 42/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0703 - accuracy: 0.9787 - val_loss: 0.0727 - val_accuracy: 0.9820\n",
      "Epoch 43/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0786 - accuracy: 0.9763 - val_loss: 0.0602 - val_accuracy: 0.9890\n",
      "Epoch 44/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0670 - accuracy: 0.9789 - val_loss: 0.1497 - val_accuracy: 0.9429\n",
      "Epoch 45/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0505 - accuracy: 0.9888 - val_loss: 0.0545 - val_accuracy: 0.9898\n",
      "Epoch 46/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9945 - val_loss: 0.0363 - val_accuracy: 0.9953\n",
      "Epoch 47/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 0.9963 - val_loss: 0.0350 - val_accuracy: 0.9969\n",
      "Epoch 48/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0256 - accuracy: 0.9969 - val_loss: 0.0225 - val_accuracy: 0.9961\n",
      "Epoch 49/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0240 - accuracy: 0.9965 - val_loss: 0.0246 - val_accuracy: 0.9977\n",
      "Epoch 50/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0223 - accuracy: 0.9973 - val_loss: 0.0238 - val_accuracy: 0.9984\n",
      "Epoch 51/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0245 - accuracy: 0.9955 - val_loss: 0.0539 - val_accuracy: 0.9906\n",
      "Epoch 52/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0465 - accuracy: 0.9832 - val_loss: 0.0520 - val_accuracy: 0.9820\n",
      "Epoch 53/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1050 - accuracy: 0.9618 - val_loss: 0.1010 - val_accuracy: 0.9773\n",
      "Epoch 54/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1000 - accuracy: 0.9646 - val_loss: 0.0865 - val_accuracy: 0.9695\n",
      "Epoch 55/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0535 - accuracy: 0.9832 - val_loss: 0.0250 - val_accuracy: 0.9961\n",
      "Epoch 56/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0281 - accuracy: 0.9949 - val_loss: 0.0273 - val_accuracy: 0.9969\n",
      "Epoch 57/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0177 - accuracy: 0.9986 - val_loss: 0.0211 - val_accuracy: 0.9977\n",
      "Epoch 58/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0147 - accuracy: 0.9988 - val_loss: 0.0150 - val_accuracy: 0.9984\n",
      "Epoch 59/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0124 - accuracy: 0.9988 - val_loss: 0.0139 - val_accuracy: 0.9977\n",
      "Epoch 60/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0112 - accuracy: 0.9992 - val_loss: 0.0071 - val_accuracy: 0.9992\n",
      "Epoch 61/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0106 - accuracy: 0.9988 - val_loss: 0.0109 - val_accuracy: 0.9984\n",
      "Epoch 62/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0105 - accuracy: 0.9986 - val_loss: 0.0145 - val_accuracy: 0.9969\n",
      "Epoch 63/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0099 - accuracy: 0.9988 - val_loss: 0.0312 - val_accuracy: 0.9930\n",
      "Epoch 64/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0103 - accuracy: 0.9994 - val_loss: 0.0126 - val_accuracy: 0.9992\n",
      "Epoch 65/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9996 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9992 - val_loss: 0.0087 - val_accuracy: 0.9984\n",
      "Epoch 67/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9996 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9998 - val_loss: 0.0072 - val_accuracy: 0.9984\n",
      "Epoch 69/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 0.0475 - val_accuracy: 0.9812\n",
      "Epoch 70/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.2622 - accuracy: 0.9168 - val_loss: 0.1962 - val_accuracy: 0.9397\n",
      "Epoch 71/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9477 - val_loss: 0.0925 - val_accuracy: 0.9656\n",
      "Epoch 72/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9830 - val_loss: 0.0216 - val_accuracy: 0.9953\n",
      "Epoch 73/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9965 - val_loss: 0.0152 - val_accuracy: 0.9984\n",
      "Epoch 74/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0130 - accuracy: 0.9986 - val_loss: 0.0118 - val_accuracy: 0.9992\n",
      "Epoch 75/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.9998 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0078 - accuracy: 0.9998 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0067 - accuracy: 0.9998 - val_loss: 0.0066 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9992\n",
      "Epoch 83/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0043 - accuracy: 0.9996 - val_loss: 0.0048 - val_accuracy: 0.9984\n",
      "Epoch 84/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9992\n",
      "Epoch 85/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 0.9998 - val_loss: 0.0045 - val_accuracy: 0.9992\n",
      "Epoch 86/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.0044 - val_accuracy: 0.9992\n",
      "Epoch 88/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0043 - accuracy: 0.9994 - val_loss: 0.0092 - val_accuracy: 0.9992\n",
      "Epoch 89/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.1565 - accuracy: 0.9568 - val_loss: 0.4518 - val_accuracy: 0.8654\n",
      "Epoch 90/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.2184 - accuracy: 0.9337 - val_loss: 0.0875 - val_accuracy: 0.9624\n",
      "Epoch 91/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0597 - accuracy: 0.9763 - val_loss: 0.0422 - val_accuracy: 0.9851\n",
      "Epoch 92/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0251 - accuracy: 0.9941 - val_loss: 0.0229 - val_accuracy: 0.9945\n",
      "Epoch 93/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0102 - accuracy: 0.9996 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.4619 - accuracy: 0.6267\n",
      "Loss: 3.461904287338257, Accuracy: 0.6266986131668091\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "F1 Score: 0.6252850517124858\n",
      "Confusion Matrix:\n",
      "[[211 241]\n",
      " [226 573]]\n"
     ]
    }
   ],
   "source": [
    "# Set seed\n",
    "random.seed(42)\n",
    "\n",
    "# Define model\n",
    "model_2 = Sequential([\n",
    "    Dense(57, activation='relu', input_shape=(57,)),  \n",
    "    Dense(30, activation='relu'), \n",
    "    Dense(15, activation='relu'), \n",
    "    Dense(len(np.unique(y_numeric)), activation='softmax') \n",
    "])\n",
    "\n",
    "\n",
    "# Compile model \n",
    "model_2.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model \n",
    "model_2.fit(X_train_resampled, y_train_resampled, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate model \n",
    "loss_2, accuracy_2 = model_2.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss_2}, Accuracy: {accuracy_2}')\n",
    "\n",
    "# Predict y\n",
    "y_pred_2 = model_2.predict(X_test)\n",
    "y_pred_classes_2 = np.argmax(y_pred_2, axis=1)\n",
    "\n",
    "# F1 score and confusion matrix\n",
    "f1_2 = f1_score(y_test, y_pred_classes_2, average='weighted')\n",
    "conf_matrix_2 = confusion_matrix(y_test, y_pred_classes_2)\n",
    "\n",
    "print(f'F1 Score: {f1_2}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "160/160 [==============================] - 2s 5ms/step - loss: 0.6364 - accuracy: 0.6421 - val_loss: 0.7549 - val_accuracy: 0.4014\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.5602 - accuracy: 0.7155 - val_loss: 0.7878 - val_accuracy: 0.4178\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.5399 - accuracy: 0.7276 - val_loss: 0.6945 - val_accuracy: 0.4765\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.5224 - accuracy: 0.7413 - val_loss: 0.6782 - val_accuracy: 0.5196\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5048 - accuracy: 0.7476 - val_loss: 0.7939 - val_accuracy: 0.4249\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.4874 - accuracy: 0.7654 - val_loss: 0.6766 - val_accuracy: 0.5250\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.4716 - accuracy: 0.7753 - val_loss: 0.6852 - val_accuracy: 0.5407\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.4528 - accuracy: 0.7875 - val_loss: 0.5942 - val_accuracy: 0.6041\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.4293 - accuracy: 0.7978 - val_loss: 0.5014 - val_accuracy: 0.6956\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.4098 - accuracy: 0.8092 - val_loss: 0.5664 - val_accuracy: 0.6565\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.3828 - accuracy: 0.8295 - val_loss: 0.5626 - val_accuracy: 0.6487\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.3602 - accuracy: 0.8423 - val_loss: 0.5313 - val_accuracy: 0.6862\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.3392 - accuracy: 0.8532 - val_loss: 0.4660 - val_accuracy: 0.7441\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.3153 - accuracy: 0.8650 - val_loss: 0.4683 - val_accuracy: 0.7496\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.2957 - accuracy: 0.8718 - val_loss: 0.3530 - val_accuracy: 0.8169\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.2790 - accuracy: 0.8824 - val_loss: 0.4028 - val_accuracy: 0.8005\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.2603 - accuracy: 0.8947 - val_loss: 0.3721 - val_accuracy: 0.8232\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.2340 - accuracy: 0.9123 - val_loss: 0.2256 - val_accuracy: 0.9030\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.2182 - accuracy: 0.9149 - val_loss: 0.2322 - val_accuracy: 0.9045\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1991 - accuracy: 0.9272 - val_loss: 0.2220 - val_accuracy: 0.8967\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1831 - accuracy: 0.9307 - val_loss: 0.2582 - val_accuracy: 0.8834\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1655 - accuracy: 0.9427 - val_loss: 0.1773 - val_accuracy: 0.9272\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1478 - accuracy: 0.9501 - val_loss: 0.1816 - val_accuracy: 0.9288\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.1363 - accuracy: 0.9532 - val_loss: 0.2055 - val_accuracy: 0.9077\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1301 - accuracy: 0.9534 - val_loss: 0.1187 - val_accuracy: 0.9609\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1251 - accuracy: 0.9548 - val_loss: 0.1797 - val_accuracy: 0.9280\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1237 - accuracy: 0.9546 - val_loss: 0.1389 - val_accuracy: 0.9523\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1147 - accuracy: 0.9614 - val_loss: 0.1316 - val_accuracy: 0.9515\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9718 - val_loss: 0.1117 - val_accuracy: 0.9546\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0869 - accuracy: 0.9746 - val_loss: 0.1064 - val_accuracy: 0.9577\n",
      "Epoch 31/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0749 - accuracy: 0.9763 - val_loss: 0.0658 - val_accuracy: 0.9875\n",
      "Epoch 32/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0623 - accuracy: 0.9847 - val_loss: 0.0812 - val_accuracy: 0.9765\n",
      "Epoch 33/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0589 - accuracy: 0.9838 - val_loss: 0.0499 - val_accuracy: 0.9859\n",
      "Epoch 34/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0556 - accuracy: 0.9847 - val_loss: 0.0704 - val_accuracy: 0.9781\n",
      "Epoch 35/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9787 - val_loss: 0.1304 - val_accuracy: 0.9624\n",
      "Epoch 36/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1145 - accuracy: 0.9566 - val_loss: 0.1436 - val_accuracy: 0.9397\n",
      "Epoch 37/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1065 - accuracy: 0.9628 - val_loss: 0.1200 - val_accuracy: 0.9468\n",
      "Epoch 38/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0771 - accuracy: 0.9769 - val_loss: 0.0706 - val_accuracy: 0.9757\n",
      "Epoch 39/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9902 - val_loss: 0.0270 - val_accuracy: 0.9961\n",
      "Epoch 40/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0288 - accuracy: 0.9959 - val_loss: 0.0285 - val_accuracy: 0.9961\n",
      "Epoch 41/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0219 - accuracy: 0.9973 - val_loss: 0.0217 - val_accuracy: 0.9969\n",
      "Epoch 42/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0180 - accuracy: 0.9986 - val_loss: 0.0171 - val_accuracy: 0.9961\n",
      "Epoch 43/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0167 - accuracy: 0.9977 - val_loss: 0.0354 - val_accuracy: 0.9922\n",
      "Epoch 44/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0187 - accuracy: 0.9977 - val_loss: 0.0259 - val_accuracy: 0.9953\n",
      "Epoch 45/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.1063 - accuracy: 0.9652 - val_loss: 0.2949 - val_accuracy: 0.9045\n",
      "Epoch 46/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.1625 - accuracy: 0.9436 - val_loss: 0.1218 - val_accuracy: 0.9468\n",
      "Epoch 47/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.1024 - accuracy: 0.9620 - val_loss: 0.1334 - val_accuracy: 0.9468\n",
      "Epoch 48/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9812 - val_loss: 0.0447 - val_accuracy: 0.9844\n",
      "Epoch 49/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0324 - accuracy: 0.9924 - val_loss: 0.0328 - val_accuracy: 0.9937\n",
      "Epoch 50/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9975 - val_loss: 0.0138 - val_accuracy: 0.9977\n",
      "Epoch 51/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9984 - val_loss: 0.0143 - val_accuracy: 0.9977\n",
      "Epoch 52/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0106 - accuracy: 0.9994 - val_loss: 0.0106 - val_accuracy: 0.9992\n",
      "Epoch 53/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0090 - accuracy: 0.9996 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0082 - accuracy: 0.9998 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0073 - accuracy: 0.9998 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9998 - val_loss: 0.0089 - val_accuracy: 0.9992\n",
      "Epoch 57/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9996 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0070 - accuracy: 0.9994 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9988 - val_loss: 0.0198 - val_accuracy: 0.9945\n",
      "Epoch 60/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1268 - accuracy: 0.9638 - val_loss: 0.4177 - val_accuracy: 0.8991\n",
      "Epoch 61/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.2456 - accuracy: 0.9211 - val_loss: 0.2760 - val_accuracy: 0.8991\n",
      "Epoch 62/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1036 - accuracy: 0.9593 - val_loss: 0.0445 - val_accuracy: 0.9883\n",
      "Epoch 63/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0428 - accuracy: 0.9881 - val_loss: 0.0177 - val_accuracy: 0.9969\n",
      "Epoch 64/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0203 - accuracy: 0.9961 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9994 - val_loss: 0.0116 - val_accuracy: 0.9984\n",
      "Epoch 66/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0083 - accuracy: 0.9994 - val_loss: 0.0085 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9998 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0054 - accuracy: 0.9998 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0048 - accuracy: 0.9998 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
      "Epoch 71/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0045 - accuracy: 0.9996 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
      "Epoch 72/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.9998 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 0.9998 - val_loss: 0.0048 - val_accuracy: 0.9992\n",
      "Epoch 75/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0552 - accuracy: 0.9832 - val_loss: 0.5486 - val_accuracy: 0.8474\n",
      "Epoch 77/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.3440 - accuracy: 0.9033 - val_loss: 0.1468 - val_accuracy: 0.9452\n",
      "Epoch 78/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.1421 - accuracy: 0.9548 - val_loss: 0.1115 - val_accuracy: 0.9609\n",
      "Epoch 79/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0528 - accuracy: 0.9843 - val_loss: 0.0531 - val_accuracy: 0.9875\n",
      "Epoch 80/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0259 - accuracy: 0.9945 - val_loss: 0.0124 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0129 - accuracy: 0.9990 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0057 - val_accuracy: 0.9992\n",
      "Epoch 88/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 0.0043 - val_accuracy: 0.9992\n",
      "Epoch 89/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 0.9998 - val_loss: 0.0054 - val_accuracy: 0.9992\n",
      "Epoch 90/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0032 - accuracy: 0.9998 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0165 - accuracy: 0.9955 - val_loss: 0.0048 - val_accuracy: 0.9984\n",
      "Epoch 92/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1638 - accuracy: 0.9442 - val_loss: 0.0786 - val_accuracy: 0.9703\n",
      "Epoch 93/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1500 - accuracy: 0.9532 - val_loss: 0.1482 - val_accuracy: 0.9484\n",
      "Epoch 94/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0812 - accuracy: 0.9706 - val_loss: 0.0451 - val_accuracy: 0.9812\n",
      "Epoch 95/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0277 - accuracy: 0.9926 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0112 - accuracy: 0.9992 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0062 - accuracy: 0.9998 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
      "40/40 [==============================] - 0s 2ms/step - loss: 3.0062 - accuracy: 0.6419\n",
      "Loss: 3.0062224864959717, Accuracy: 0.6418864727020264\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "F1 Score: 0.6381885169289934\n",
      "Confusion Matrix:\n",
      "[[209 243]\n",
      " [205 594]]\n"
     ]
    }
   ],
   "source": [
    "# Set seed\n",
    "random.seed(42)\n",
    "\n",
    "# Define\n",
    "model_3 = Sequential([\n",
    "    Dense(57, activation='relu', input_shape=(57,)),  \n",
    "    Dense(40, activation='relu'), \n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='relu'), \n",
    "    Dense(len(np.unique(y_numeric)), activation='softmax') \n",
    "])\n",
    "\n",
    "\n",
    "# Compile model \n",
    "model_3.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model \n",
    "model_3.fit(X_train_resampled, y_train_resampled, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate model \n",
    "loss_3, accuracy_3 = model_3.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss_3}, Accuracy: {accuracy_3}')\n",
    "\n",
    "# Predict y\n",
    "y_pred_3 = model_3.predict(X_test)\n",
    "y_pred_classes_3 = np.argmax(y_pred_3, axis=1)\n",
    "\n",
    "# F1 score and confusion matrix\n",
    "f1_3 = f1_score(y_test, y_pred_classes_3, average='weighted')\n",
    "conf_matrix_3 = confusion_matrix(y_test, y_pred_classes_3)\n",
    "\n",
    "print(f'F1 Score: {f1_3}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "160/160 [==============================] - 3s 5ms/step - loss: 0.6030 - accuracy: 0.6855 - val_loss: 0.7825 - val_accuracy: 0.4444\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.5599 - accuracy: 0.7192 - val_loss: 0.7601 - val_accuracy: 0.4460\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.5416 - accuracy: 0.7344 - val_loss: 0.7915 - val_accuracy: 0.3967\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7403 - val_loss: 0.7934 - val_accuracy: 0.4507\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.5083 - accuracy: 0.7544 - val_loss: 0.7825 - val_accuracy: 0.4851\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.4884 - accuracy: 0.7679 - val_loss: 0.7305 - val_accuracy: 0.5070\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.4705 - accuracy: 0.7810 - val_loss: 0.6488 - val_accuracy: 0.5869\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.4474 - accuracy: 0.7947 - val_loss: 0.6230 - val_accuracy: 0.6072\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.4244 - accuracy: 0.8074 - val_loss: 0.5377 - val_accuracy: 0.6808\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.4053 - accuracy: 0.8223 - val_loss: 0.5795 - val_accuracy: 0.6635\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.3775 - accuracy: 0.8370 - val_loss: 0.3936 - val_accuracy: 0.7817\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.3542 - accuracy: 0.8470 - val_loss: 0.4720 - val_accuracy: 0.7316\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.3277 - accuracy: 0.8609 - val_loss: 0.4214 - val_accuracy: 0.7754\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.8748 - val_loss: 0.3999 - val_accuracy: 0.7966\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.2908 - accuracy: 0.8783 - val_loss: 0.4029 - val_accuracy: 0.8013\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.2636 - accuracy: 0.8939 - val_loss: 0.3834 - val_accuracy: 0.8091\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.2412 - accuracy: 0.9098 - val_loss: 0.2573 - val_accuracy: 0.8905\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.2200 - accuracy: 0.9160 - val_loss: 0.3038 - val_accuracy: 0.8623\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.2042 - accuracy: 0.9231 - val_loss: 0.2800 - val_accuracy: 0.8772\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.1913 - accuracy: 0.9249 - val_loss: 0.3206 - val_accuracy: 0.8592\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1831 - accuracy: 0.9288 - val_loss: 0.2441 - val_accuracy: 0.8951\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1705 - accuracy: 0.9346 - val_loss: 0.1859 - val_accuracy: 0.9225\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1599 - accuracy: 0.9376 - val_loss: 0.1643 - val_accuracy: 0.9241\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.1532 - accuracy: 0.9415 - val_loss: 0.1704 - val_accuracy: 0.9225\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1366 - accuracy: 0.9521 - val_loss: 0.1189 - val_accuracy: 0.9523\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1128 - accuracy: 0.9603 - val_loss: 0.1017 - val_accuracy: 0.9640\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1087 - accuracy: 0.9616 - val_loss: 0.0882 - val_accuracy: 0.9695\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1025 - accuracy: 0.9661 - val_loss: 0.1563 - val_accuracy: 0.9405\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.1039 - accuracy: 0.9640 - val_loss: 0.1079 - val_accuracy: 0.9593\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.1070 - accuracy: 0.9597 - val_loss: 0.1185 - val_accuracy: 0.9585\n",
      "Epoch 31/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.1016 - accuracy: 0.9642 - val_loss: 0.0885 - val_accuracy: 0.9710\n",
      "Epoch 32/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1242 - accuracy: 0.9581 - val_loss: 0.1011 - val_accuracy: 0.9632\n",
      "Epoch 33/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.1132 - accuracy: 0.9575 - val_loss: 0.0868 - val_accuracy: 0.9734\n",
      "Epoch 34/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0947 - accuracy: 0.9661 - val_loss: 0.1850 - val_accuracy: 0.9202\n",
      "Epoch 35/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0675 - accuracy: 0.9773 - val_loss: 0.0871 - val_accuracy: 0.9703\n",
      "Epoch 36/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0535 - accuracy: 0.9851 - val_loss: 0.0693 - val_accuracy: 0.9703\n",
      "Epoch 37/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0872 - accuracy: 0.9706 - val_loss: 0.0689 - val_accuracy: 0.9820\n",
      "Epoch 38/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0659 - accuracy: 0.9773 - val_loss: 0.0684 - val_accuracy: 0.9687\n",
      "Epoch 39/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0711 - accuracy: 0.9759 - val_loss: 0.0861 - val_accuracy: 0.9750\n",
      "Epoch 40/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0754 - accuracy: 0.9720 - val_loss: 0.0443 - val_accuracy: 0.9875\n",
      "Epoch 41/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0618 - accuracy: 0.9773 - val_loss: 0.0721 - val_accuracy: 0.9797\n",
      "Epoch 42/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0750 - accuracy: 0.9744 - val_loss: 0.0579 - val_accuracy: 0.9789\n",
      "Epoch 43/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0423 - accuracy: 0.9863 - val_loss: 0.0258 - val_accuracy: 0.9914\n",
      "Epoch 44/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0444 - accuracy: 0.9863 - val_loss: 0.0386 - val_accuracy: 0.9867\n",
      "Epoch 45/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0409 - accuracy: 0.9888 - val_loss: 0.0438 - val_accuracy: 0.9875\n",
      "Epoch 46/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0573 - accuracy: 0.9830 - val_loss: 0.0622 - val_accuracy: 0.9742\n",
      "Epoch 47/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0720 - accuracy: 0.9728 - val_loss: 0.0580 - val_accuracy: 0.9828\n",
      "Epoch 48/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0483 - accuracy: 0.9857 - val_loss: 0.0522 - val_accuracy: 0.9875\n",
      "Epoch 49/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0500 - accuracy: 0.9843 - val_loss: 0.0770 - val_accuracy: 0.9695\n",
      "Epoch 50/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0643 - accuracy: 0.9773 - val_loss: 0.0431 - val_accuracy: 0.9844\n",
      "Epoch 51/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0542 - accuracy: 0.9826 - val_loss: 0.0419 - val_accuracy: 0.9851\n",
      "Epoch 52/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0578 - accuracy: 0.9804 - val_loss: 0.0353 - val_accuracy: 0.9851\n",
      "Epoch 53/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0523 - accuracy: 0.9836 - val_loss: 0.0825 - val_accuracy: 0.9679\n",
      "Epoch 54/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0348 - accuracy: 0.9890 - val_loss: 0.0199 - val_accuracy: 0.9930\n",
      "Epoch 55/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy: 0.9959 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.9986 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0054 - val_accuracy: 0.9992\n",
      "Epoch 59/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0038 - accuracy: 0.9996 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 0.9992\n",
      "Epoch 62/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0031 - accuracy: 0.9996 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 9.9418e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0105 - val_accuracy: 0.9969\n",
      "Epoch 69/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.2075 - accuracy: 0.9599 - val_loss: 0.2674 - val_accuracy: 0.9061\n",
      "Epoch 70/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.3467 - accuracy: 0.8763 - val_loss: 0.2223 - val_accuracy: 0.8928\n",
      "Epoch 71/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1415 - accuracy: 0.9458 - val_loss: 0.0455 - val_accuracy: 0.9859\n",
      "Epoch 72/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0756 - accuracy: 0.9738 - val_loss: 0.1011 - val_accuracy: 0.9593\n",
      "Epoch 73/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0463 - accuracy: 0.9853 - val_loss: 0.0213 - val_accuracy: 0.9945\n",
      "Epoch 74/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0345 - accuracy: 0.9912 - val_loss: 0.0334 - val_accuracy: 0.9883\n",
      "Epoch 75/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.0067 - val_accuracy: 0.9984\n",
      "Epoch 76/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0286 - accuracy: 0.9932 - val_loss: 0.0185 - val_accuracy: 0.9961\n",
      "Epoch 77/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0424 - accuracy: 0.9859 - val_loss: 0.0545 - val_accuracy: 0.9765\n",
      "Epoch 78/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0435 - accuracy: 0.9875 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0437 - accuracy: 0.9863 - val_loss: 0.0758 - val_accuracy: 0.9773\n",
      "Epoch 80/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0731 - accuracy: 0.9740 - val_loss: 0.1526 - val_accuracy: 0.9437\n",
      "Epoch 81/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0459 - accuracy: 0.9838 - val_loss: 0.0662 - val_accuracy: 0.9718\n",
      "Epoch 82/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0458 - accuracy: 0.9832 - val_loss: 0.0608 - val_accuracy: 0.9757\n",
      "Epoch 83/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9867 - val_loss: 0.0197 - val_accuracy: 0.9930\n",
      "Epoch 84/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0167 - accuracy: 0.9957 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9990 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 9.0587e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 6.7847e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 7.8983e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "160/160 [==============================] - 0s 3ms/step - loss: 7.7526e-04 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9992\n",
      "Epoch 95/100\n",
      "160/160 [==============================] - 1s 4ms/step - loss: 0.0170 - accuracy: 0.9955 - val_loss: 0.1838 - val_accuracy: 0.9405\n",
      "Epoch 96/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.3219 - accuracy: 0.9012 - val_loss: 0.1410 - val_accuracy: 0.9405\n",
      "Epoch 97/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.1135 - accuracy: 0.9587 - val_loss: 0.0568 - val_accuracy: 0.9812\n",
      "Epoch 98/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0454 - accuracy: 0.9869 - val_loss: 0.0156 - val_accuracy: 0.9953\n",
      "Epoch 99/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0334 - accuracy: 0.9881 - val_loss: 0.0556 - val_accuracy: 0.9773\n",
      "Epoch 100/100\n",
      "160/160 [==============================] - 1s 3ms/step - loss: 0.0172 - accuracy: 0.9955 - val_loss: 0.0096 - val_accuracy: 0.9992\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 2.8021 - accuracy: 0.6443\n",
      "Loss: 2.802072286605835, Accuracy: 0.6442845463752747\n",
      "40/40 [==============================] - 0s 2ms/step\n",
      "F1 Score: 0.6431247931574672\n",
      "Confusion Matrix:\n",
      "[[223 229]\n",
      " [216 583]]\n"
     ]
    }
   ],
   "source": [
    "# Set seed\n",
    "random.seed(42)\n",
    "\n",
    "# Define model\n",
    "model_4 = Sequential([\n",
    "    Dense(57, activation='relu', input_shape=(57,)),  \n",
    "    Dense(40, activation='relu'), \n",
    "    Dense(30, activation='relu'), \n",
    "    Dense(20, activation='relu'),\n",
    "    Dense(10, activation='relu'), \n",
    "    Dense(len(np.unique(y_numeric)), activation='softmax') \n",
    "])\n",
    "\n",
    "\n",
    "# Compile model \n",
    "model_4.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model \n",
    "model_4.fit(X_train_resampled, y_train_resampled, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate model \n",
    "loss_4, accuracy_4 = model_4.evaluate(X_test, y_test)\n",
    "print(f'Loss: {loss_4}, Accuracy: {accuracy_4}')\n",
    "\n",
    "# Predict y\n",
    "y_pred_4 = model_4.predict(X_test)\n",
    "y_pred_classes_4 = np.argmax(y_pred_4, axis=1)\n",
    "\n",
    "# F1 score and confusion matrix\n",
    "f1_4 = f1_score(y_test, y_pred_classes_4, average='weighted')\n",
    "conf_matrix_4 = confusion_matrix(y_test, y_pred_classes_4)\n",
    "\n",
    "print(f'F1 Score: {f1_4}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1: 1 layered model\n",
      "Loss: 3.090261220932007, Accuracy: 0.6195043921470642\n",
      "F1 Score: 0.6189449031724862\n",
      "Confusion Matrix:\n",
      "[[211 241]\n",
      " [235 564]]\n",
      "Model_2: 2 layered model\n",
      "Loss: 3.461904287338257, Accuracy: 0.6266986131668091\n",
      "F1 Score: 0.6252850517124858\n",
      "Confusion Matrix:\n",
      "[[211 241]\n",
      " [226 573]]\n",
      "Model_3: 3 layered model\n",
      "Loss: 3.0062224864959717, Accuracy: 0.6418864727020264\n",
      "F1 Score: 0.6381885169289934\n",
      "Confusion Matrix:\n",
      "[[209 243]\n",
      " [205 594]]\n",
      "Model_4: 4 layered model\n",
      "Loss: 2.802072286605835, Accuracy: 0.6442845463752747\n",
      "F1 Score: 0.6431247931574672\n",
      "Confusion Matrix:\n",
      "[[223 229]\n",
      " [216 583]]\n"
     ]
    }
   ],
   "source": [
    "# Compare the differnet versions of the model\n",
    "print('Model_1: 1 layered model')\n",
    "print(f'Loss: {loss_1}, Accuracy: {accuracy_1}')\n",
    "print(f'F1 Score: {f1_1}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_1)\n",
    "\n",
    "print('Model_2: 2 layered model')\n",
    "print(f'Loss: {loss_2}, Accuracy: {accuracy_2}')\n",
    "print(f'F1 Score: {f1_2}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_2)\n",
    "\n",
    "print('Model_3: 3 layered model')\n",
    "print(f'Loss: {loss_3}, Accuracy: {accuracy_3}')\n",
    "print(f'F1 Score: {f1_3}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_3)\n",
    "\n",
    "print('Model_4: 4 layered model')\n",
    "print(f'Loss: {loss_4}, Accuracy: {accuracy_4}')\n",
    "print(f'F1 Score: {f1_4}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the feature importance\n",
    "weights = model_4.get_weights()\n",
    "\n",
    "feature_importance = np.sum(np.abs(weights[0]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              feature  importance\n",
      "39                          DocTellColorectalTests_No   11.734979\n",
      "0                                                 Age   11.071309\n",
      "8                                           Education   11.061773\n",
      "7                                        DrinksPerDay   10.848192\n",
      "9                                      FreqGoProvider   10.625103\n",
      "41                              QualityCare_Excellent   10.496998\n",
      "1                                                AsAm   10.416945\n",
      "31  DelayNeededCare_I did not need any medical car...   10.330906\n",
      "5                                    DrinkDaysPerWeek   10.330372\n",
      "40                         DocTellColorectalTests_Yes   10.305519\n",
      "27                                        WhenPapTest   10.225266\n",
      "15                             MedConditions_Diabetes   10.111240\n",
      "49  SunEffectAfter1Hour_Burn mildly with some or n...   10.086460\n",
      "10                                   HealthInsurance2   10.067721\n",
      "47                                SmokeNow_Not at all    9.996235\n",
      "6                                   DrinksOneOccasion    9.948864\n",
      "16                               MedConditions_HighBP    9.948708\n",
      "37                                    DocTalkLDCT_Yes    9.945602\n",
      "29                                 BirthGender_Female    9.866998\n",
      "11                                   HeardHPVVaccine2    9.844175\n",
      "38  DocTellColorectalTests_I have never discussed ...    9.712545\n",
      "20                                           Smoke100    9.634459\n",
      "50  SunEffectAfter1Hour_Get a severe sunburn with ...    9.628492\n",
      "12                            HPVCauseCancer_Cervical    9.546444\n",
      "17                       MedConditions_HeartCondition    9.476402\n",
      "52  SunEffectAfter1Hour_Nothing would happen to my...    9.468578\n",
      "43                                   QualityCare_Good    9.434495\n",
      "18                          MedConditions_LungDisease    9.426135\n",
      "36                                     DocTalkLDCT_No    9.403682\n",
      "51  SunEffectAfter1Hour_Have a moderate sunburn wi...    9.379796\n",
      "28                                              White    9.359673\n",
      "32  DelayNeededCare_No, I received the medical car...    9.227370\n",
      "30                                   BirthGender_Male    9.158136\n",
      "2                                             AmerInd    9.118484\n",
      "14                                       IncomeRanges    9.083355\n",
      "22                                    Sunburned_Other    9.071525\n",
      "46                                  SmokeNow_Everyday    8.956780\n",
      "45                              QualityCare_Very good    8.955975\n",
      "24                                     Sunburned_Work    8.882437\n",
      "23                                      Sunburned_Rec    8.849685\n",
      "13                                               Hisp    8.779468\n",
      "35        DocTalkLDCT_I have never heard of this test    8.776832\n",
      "26                                       UsedECigEver    8.722700\n",
      "19                                          OthPacIsl    8.722306\n",
      "42                                   QualityCare_Fair    8.685675\n",
      "54                                UseECigNow_Everyday    8.612341\n",
      "4                                               Black    8.596095\n",
      "34                              DocTalkLDCT_Dont know    8.553394\n",
      "25                                     TimesSunburned    8.442356\n",
      "33                                DelayNeededCare_Yes    8.423413\n",
      "48                                 SmokeNow_Some days    8.226105\n",
      "56                               UseECigNow_Some days    8.165355\n",
      "53    SunEffectAfter1Hour_Turn darker without sunburn    8.120252\n",
      "21                                   Sunburned_Active    7.674853\n",
      "3                                    AvgDrinksPerWeek    7.651299\n",
      "44                                   QualityCare_Poor    7.300845\n",
      "55                              UseECigNow_Not at all    7.044405\n"
     ]
    }
   ],
   "source": [
    "# Define the features\n",
    "features = df.drop(['EverHadCancer', 'FamilyEverHadCancer2'], axis=1).columns\n",
    "\n",
    "# Convert feature importance to a DataFrame\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': feature_importance\n",
    "})\n",
    "\n",
    "# Sort by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to C:\\Users\\kyram\\OneDrive\\School\\FNN2_importance.json\n"
     ]
    }
   ],
   "source": [
    "# Convert DataFrame to a dictionary\n",
    "FNN_importance = {\n",
    "    'public': feature_importance_df.to_dict(),  \n",
    "}\n",
    "# Create path\n",
    "save_path = r\"C:\\Users\\kyram\\OneDrive\\School\\FNN2_importance.json\"\n",
    "\n",
    "# Confirm the dictionary exists\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "# Save the data to a JSON file\n",
    "with open(save_path, 'w') as file:\n",
    "    json.dump(FNN_importance, file)\n",
    "\n",
    "print(f\"Data successfully saved to {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
